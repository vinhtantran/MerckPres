<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Presentation at Merck  An Overview of Monothetic Cluster Analysis and Two Collaboration Projects</title>
    <meta charset="utf-8" />
    <meta name="author" content="Tan Tran, PhD" />
    <meta name="date" content="2019-09-12" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/tamu-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link rel="stylesheet" href="msu.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# <small>Presentation at Merck</small><br/><br/>An Overview of Monothetic Cluster Analysis and Two Collaboration Projects
### Tan Tran, PhD
### September 12, 2019

---






# Introduction
## Clustering

* Unsupervised learning techniques for grouping (multivariate) responses with the goal of:
  * homogeneity — internal cohesion
  * separation — external isolation
  
* When to use clustering:
  * Find underlying patterns where little or no information about the data are known or to compare to known groups
  * Prediction of cluster membership based on the common characteristics of the clusters
  
* "A classification of a set of objects is not like a scientific theory and should perhaps be judged largely on its usefulness [...]." (Everitt, Landau, Leese, et al., 2011)

???

Test the font size

---
## Two Clustering Techniques

* Optimization clustering techniques

  * The number of clusters, `\(K\)`, have to be pre-determined
  * Move the objects between clusters as long as it improves the criterion
  * `\(k\)`-means and partitioning around medoids (PAM, or `\(k\)`-medoids) are two examples of this technique
  
* Hierarchical clustering techniques

  * Distance measures between objects and between clusters must be defined
    * single linkage, complete linkage, Ward's method, etc.
  * Objects are fused together (agglomerative), or separated from each 
other (divisive) in each step based on the distance metric
  * The result is usually presented by dendrogram

---
## An Example: `\(k\)`-Means

Data from Barbour, Kosa, Komori, et al. (2017) cerebro-spinal fluid (CSF) biomarker data 
set with `\(n = 225\)` subjects. The variables of interest are the standardized log ratios of 22 biomarkers (proteins).
* Multiple Sclerosis (MS) and non-MS patients are known
* `\(Q = 2\)` proteins are displayed to visually demonstrate the method

&lt;img src="figure/kmeanhier-1.png" width="45%" style="display: block; margin: auto;" /&gt;

---

## An Example: Hierarchical with Ward's Method

&lt;img src="figure/hclust-1.png" width="50%" /&gt;&lt;img src="figure/hclust-2.png" width="50%" /&gt;

---

## Polythetic vs. Monothetic Clustering

* Popular methods like k-means and Ward's are **polythetic methods**
  * Clustered using the combined information of variables
  * Observations in a cluster are similar "on average" but may share no common characteristics

* There are also **monothetic divisive methods**
  * Data are bi-partitioned based on values of one variable at a time
  * Observations share common characteristics: in the same interval or category

---

## Monothetic Clustering Algorithm

* Introduced in Chavent (1998) and Piccarreta and Billari (2007), inspired by classification and regression trees (Breiman, Friedman, Stone, et al., 1984)

* A global criterion called **inertia** for a cluster `\(C_k\)` is defined as 
`$$I(C_k) = \frac{1}{n_k} \sum_{(i, j) \in C_k, i &gt; j}  d^2(\mathbf{y_i},\mathbf{y_j})$$`
where `\(d(\mathbf{y_i},\mathbf{y_j})\)` is the distance between observations `\(\mathbf{y_i}\)` and `\(\mathbf{y_j}\)` and `\(n_k\)` is the cluster size

* Let `\(s\)` be a binary split dividing a cluster `\(C_k\)` into two clusters `\(C_{kL}\)` and `\(C_{kR}\)`. The decrease in inertia is 
`$$\Delta I(s, C_k) = I(C_k) - I(C_{kL}) - I(C_{kR})$$`

* The best split is selected as
$$s^*(C_k) = \arg \max_s {\Delta I(s,C_k)} $$


---

## Properties of Monothetic Clustering
* Inertia is a global optimization criterion

* Bi-partition observations based on one variable at a time, making the method monothetic

* Defines rules for cluster membership
  * Easy classification of new members
  
* For the CSF data, monothetic clustering can be useful to allow classification into groups with shared characteristics that *might* relate to disease presence/absence

???

Shared characteristics in the second bullet.

---

## Monothetic Clustering on the CSF Data

&lt;img src="figure/monodemo2-1.png" width="50%" /&gt;&lt;img src="figure/monodemo2-2.png" width="50%" /&gt;

???

QUICK!!!

---

## One more split
&lt;img src="figure/monodemo3-1.png" width="50%" /&gt;&lt;img src="figure/monodemo3-2.png" width="50%" /&gt;

???

QUICK!!!

---

# Clustering Functional Data
## Arctic Sea Ice Extent Data

* Arctic Sea ice extent data set has been collected by National Snow &amp; Ice Data Center since November 1978 (Fetterer, Knowles, Meier, et al., 2018)

&lt;img src="figure/sat-1.png" width="80%" style="display: block; margin: auto;" /&gt;

???

1987 change

---

## Raw Arctic Ice Extent

&lt;img src="figure/iceextent-1.png" width="100%" /&gt;

???

Decreasing trend AND seasonal, dip...

---
## Functional Data

* When measurements were taken over some ordered index, such as time, frequency, or space (Ramsay and Silverman, 2005)
  * Responses are continuous as a function of the index
  * Possibly high frequency of observations and smooth underlying process or observations
  
* Observations are converted to functional data using basis functions:
  * **B-splines basis**, Fourier basis, Wavelets, etc.
  
* Penalized B-splines with knots at every day optimized with cross-validation for each curve

* Ice extent area in a year can be expressed as a function of time, `\(y_i(t)\)`
  * where `\(i\)` is the year, `\(t\)` is the day of year, and `\(y\)` is the ice extent at that time point

---

## Smoothed and Interpolated Curves

&lt;img src="figure/smootheny-1.png" width="100%" /&gt;

???

Penalized B-splines with knots at every day to optimized for **each curve**

---

## Clustering Functional Data

* The `\(L_2\)` distance matrix can be be calculated and used for non-functional clustering algorithms
    `$$d(y_i, y_j) = \sqrt{\int_T [y_i(t) – y_j(t)]^2 dt}$$`

* Monothetic clustering uses functional data in their discretized form
  * Transform the data into functional presentations
  * Data are then estimated to a common fine grid of `\(t\)`, `\(y_{it}\)` from `\(y_i(t)\)`
  * Missing values are imputed and the data set is balanced with `\(t = 1, \ldots, 366\)` days for all years

---
## Monothetic Clustering Result

* Evaluate functional data for each year, cluster years 
    using the 366 "variables" (days) each year
* Splitting the data based on one variable (day) at a time
* Have to deal with many equivalent splits possible at "neighboring" 
    variables    
    
&lt;img src="figure/monosplit-1.png" width="50%" /&gt;&lt;img src="figure/monosplit-2.png" width="50%" /&gt;

???

* Reason: because so smooth, close points have same info
* Plot: High Jan, Low Jan, then High/low July and High/low July

---
## Partitioning Using Local Subregions

* By aggregating over regions of time, we develop a new clustering 
    algorithm related to monothetic clustering that is more suited to 
    functional data
* PULS recursively bi-partitions functional data using only groups 
    from subregions.
* For each subregion `\([a_1, b_1], \ldots, [a_R, b_R]\)`, calculate an `\(L_2\)` 
    distance matrix
    `$$d_R(y_i, y_j) = \sqrt{\int_{a_r}^{b_r} [y_i(t) – y_j(t)]^2 dt},$$`
* Apply a clustering algorithm (PAM, Ward's method, etc.) to create 
    2-group cluster solutions in `\(R\)` subregions
* Pick the solution that maximizes the difference in the global inertia 
* Recursively apply to the newly created clusters
    
---
## Partitioning Using Local Subregions Result



&lt;img src="figure/pulssplit-1.png" width="50%" /&gt;&lt;img src="figure/pulssplit-2.png" width="50%" /&gt;

---
## Comparison of Results and Cluster Prediction

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Name &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; PULS &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; MonoClust &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;vertical-align: top !important;" rowspan="2"&gt; High Jan, High Jul &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1979-.red[**1981**], 1983-1984, &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1979-1981, 1983-1986, 1989, &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   
   &lt;td style="text-align:left;"&gt; 1986, 1989, 1992, 1994, 1996 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1992-.red[**1994**], 1996 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;vertical-align: top !important;" rowspan="2"&gt; High Jan, Low Jul &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1985, 1991, 1993, 1995, &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1991, 1995, &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   
   &lt;td style="text-align:left;"&gt; .red[**1997**]-2004 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1997-.red[**2000**]-2004 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Low Jan, High Jul &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2005, 2008-2010, .red[**2013**], 2014 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2005, 2008-2010, .red[**2013**], 2014 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Low Jan, Low Jul &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2007, .red[**2011**], 2012, 2015-2017 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2007, .red[**2011**], 2012, 2015-2017 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

???

* Medoid year in bold
* Very similar, last two clusters are identical
* 1985, 1993 (1) to (PULS 2)

--

* One year in each decade was randomly withheld from the test data set: 
  * 1982, 1990, 2006, 2018
* Predict the cluster from monothetic clustering's splitting rule tree

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; High Jan, High Jul &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; High Jan, Low Jul &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Low Jan, High Jul &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Low Jan, Low Jul &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1982 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1990 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2006 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2018 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

???

* Monothetic clustering has clear rule so can predict

---

## Simulation Study
* Compare the performance of various clustering techniques on functional data
  * Monothetic clustering, PAM, and Ward's method
  * PULS with PAM and PULS with Ward's method on on five subregions
  
&lt;img src="figure/simulcurves-1.png" width="100%" /&gt;

* Corrected Rand Index (Rand, 1971) and Pseudo-R2 are used to evaluate
* PULS and monothetic clustering both perform better than PAM and competitive with Ward's method
* Ward's method works well both within PULS and by itself

---

## Other Problems (Not Mentioned Here)

* Choosing the number of clusters in monothetic clustering
  * A hybrid method of permutation test and an error-based method such as average silhouette width or pseudo-F

* Application on data with circular variables
  * Dissimilarity measures
  * Visualizations
  
* R packages `monoclust` and `PULS` are available on Github

---

## Possible Extensions

* Clustering the derivative of the Arctic ice extent data

* Consider the Arctic ice extent data as circular functional data

* Search algorithms improvement

&lt;img src="figure/icecirpuls-1.png" width="50%" /&gt;



---
# Statistical Consultation Collaborations: Power Analysis

* A research grant proposal to the USDA ARS Pulse Crop Health Initiative Research Project Plan

* Principal Investigator: Mary Miles, PhD, FACSM, of Montana State University

* My role: Statistician, involved in designing the analysis plan and statistical power analysis for the project

* Was aprroved for funding last week

---
## Objectives

1. **Determine the impact of pulse (green lentil and black bean) consumption on postprandial triglyceride (TG) and inflammation responses to a high-fat meal challenge.**

2. Determine the extent to which the gut microbiome and changes in the gut microbiome induced by pulse consumption influence health impacts 

3. Measure metabolomic profiles to elucidate underlying mechanisms linking pulse consumption to improved health.

---
## Study Plan

![](figure/studyplan1.png)

---
## Collaboration

1. Learn the study
  * Biological terminologies
  * Microbiome data analysis
  * Metabolomics data analysis

2. Prioritize the objective
  * Objective 1
  * Objectives 2 and 3 are explanatory
  
3. Design the analysis plan
  * Obj. 1: one-sided t-test with possible multiple testings
  * Obj. 2: PLS-DA and variable importance to specify species differentiate the two treatment groups
  * Obj. 3: untargeted analysis using XCMS and mummichog
  
4. Power analysis based on Objective 1
  * Budget limit: can only recruit 36 to 48 people

---
## Determine the Effect Size

* There was a pilot study with similar design
  * Two groups of participants: high fat responder (n = 22) and low fat responder (n = 18)
  * The high fat meal challenge was done and the change in triglyceride levels were measured several times
  * There was no 12-week experiment
  
&lt;img src="figure/generalplot-1.png" width="100%" /&gt;

---
## Max Triglyceride

&lt;img src="figure/maxplot-1.png" width="100%" /&gt;



&lt;table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; sample &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Mean &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Expected Mean After (50%) &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SD &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Effect size &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; High and Low Responders &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 87.75 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 43.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 81.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.54 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; High Responders Only &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 134.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 67.11 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 83.68 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.80 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
## Power Analysis Plot with Effect Size d = 0.54

&lt;img src="figure/obj1a-1.png" width="100%" /&gt;

---
## Another Power Analysis Calculation with d = 0.8

* Another meeting happened and the researcher agreed to screen the participants further to not include people with low high fat responder.

&lt;img src="figure/obj1c-1.png" width="100%" /&gt;

---
## Deliverables

* An interactive report to assist the researcher to decide the sample size and the power of the test.

---
# Sensitivity of Analysis Paths in MetaboAnalyst

* The Proteomics, Metabolomics and Mass Spectrometry Facility (Mass Spec) is a research lab in Montana State University

* They are funded by INBRE and usually do LC-MS analysis for many metabolomics-related projects on campus

* MetaboAnalyst (https://www.metaboanalyst.ca/) is the web application they use for statistical analysis of metabolomics data

* My role as a statistician with computer science background
  * Learn the analyses the webapp is doing
  * Understand how biochemists have been using the webapp
  * Suggest good sets of options that will give a statistically sound result
  
* This is an ongoing project

---
## Difficulties to Overcome

* Chemical and bio-chemical terminologies

* Mass spec procedures and associated data analysis problems

* Dig into R packages used by MetaboAnalyst and reproduce the results offline

* Learn how researchers have been using MetaboAnalyst and reproduce the results

* Automate the analysis process

* Do sensitivity analysis on various options

---
## Current Results

* Used the metabolomics data set from Dr. Hunts' pilot dietary project
  * Detect metabolites that differentiate the high and low fat responder groups
  
* Divided the analysis duties between domain experts and statistician
  * The biochemists to run blanks to help with filtering process
  * The statisticians to work on appropriate data transformations

* A report on sensitivity analysis with an accompanied Shiny app
  
---
## Future Work

* Learn the assumptions made by Partial Least Squares Determinant Analysis (PLS-DA)

* Give formal suggestions on what analysis paths to use for finding influencing features problems

* Move on to a different set of mass spec data with a different analysis question
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
